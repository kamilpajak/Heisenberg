# Heisenberg - Plan Refaktoryzacji

> Dokument wygenerowany na podstawie code review z dnia 2026-01-25

## Status implementacji

| Faza | Status | Data | Uwagi |
|------|--------|------|-------|
| **Faza 1** | âœ… ZakoÅ„czona | 2026-01-25 | TDD, 717 testÃ³w passed |
| **Faza 2** | âœ… ZakoÅ„czona | 2026-01-25 | TDD, 729 testÃ³w passed |
| **Faza 3** | âœ… ZakoÅ„czona | 2026-01-25 | TDD, 785 testÃ³w passed |
| **Faza 4** | â³ Opcjonalna | - | - |

---

## Podsumowanie

Heisenberg to dobrze zarchitekturyzowana aplikacja Python/FastAPI. PoniÅ¼szy plan adresuje zidentyfikowane obszary do poprawy, uporzÄ…dkowane wedÅ‚ug priorytetu i wpÅ‚ywu na system.

---

## Priorytety

| Priorytet | Problem | WysiÅ‚ek | WpÅ‚yw | Status |
|-----------|---------|---------|-------|--------|
| ğŸ”´ HIGH | Rate limiter nie skaluje siÄ™ | Åšredni | Wysoki | âœ… Naprawione |
| ğŸŸ¡ MEDIUM | Settings Å‚adowane przy kaÅ¼dym requescie | Niski | Åšredni | âœ… Naprawione |
| ğŸŸ¡ MEDIUM | Duplikacja klientÃ³w LLM | Åšredni | Åšredni | âœ… Naprawione |
| ğŸŸ¢ LOW | Globalny stan bazy danych | Åšredni | Niski | â³ Faza 4 |
| ğŸŸ¢ LOW | Zbyt szeroki `except Exception` | Niski | Niski | âœ… Naprawione |

---

## Faza 1: Quick Wins âœ…

> **ZakoÅ„czona 2026-01-25** | Implementacja TDD | 12 nowych testÃ³w | 717 testÃ³w passed

### 1.1 Cache ustawieÅ„ aplikacji âœ…

**Plik:** `src/heisenberg/backend/config.py`

**Problem:** `get_settings()` tworzy nowÄ… instancjÄ™ `Settings()` przy kaÅ¼dym wywoÅ‚aniu, powodujÄ…c powtÃ³rzony odczyt pliku `.env`.

**Zaimplementowane rozwiÄ…zanie:**

```python
from functools import lru_cache

@lru_cache
def get_settings() -> Settings:
    """Get cached settings instance."""
    return Settings()
```

**Testy:** `tests/test_phase1_refactoring.py::TestSettingsCaching` (4 testy)

**Uwaga dla testÃ³w:** UÅ¼yÄ‡ `get_settings.cache_clear()` w fixture jeÅ›li testy modyfikujÄ… zmienne Å›rodowiskowe.

---

### 1.2 ZawÄ™Å¼enie obsÅ‚ugi wyjÄ…tkÃ³w w LLM Router âœ…

**Plik:** `src/heisenberg/backend/llm/router.py`

**Problem:** Åapanie `Exception` maskuje bÅ‚Ä™dy programistyczne.

**Zaimplementowane rozwiÄ…zanie:**

```python
# Dodane importy
import httpx
from anthropic import APIError as AnthropicAPIError
from openai import APIError as OpenAIAPIError

# Tuple z wyjÄ…tkami do Å‚apania (z opcjonalnym Google API)
LLM_RECOVERABLE_ERRORS: tuple[type[Exception], ...] = (
    AnthropicAPIError,
    OpenAIAPIError,
    httpx.RequestError,
    httpx.HTTPStatusError,
)

# W metodzie analyze():
except LLM_RECOVERABLE_ERRORS as e:  # zamiast except Exception
```

**Testy:** `tests/test_phase1_refactoring.py::TestLLMRouterExceptionHandling` (8 testÃ³w)

---

## Faza 2: SkalowalnoÅ›Ä‡ âœ…

> **ZakoÅ„czona 2026-01-25** | Implementacja TDD | 12 nowych testÃ³w | 729 testÃ³w passed

### 2.1 Zabezpieczenie Rate Limitera przed race conditions âœ…

**Plik:** `src/heisenberg/backend/rate_limit.py`

**Problem:** Brak atomowoÅ›ci przy rÃ³wnoczesnych requestach; nie dziaÅ‚a z wieloma workerami.

**RozwiÄ…zanie (etap 1 - locki):**

```python
"""Rate limiting functionality for Heisenberg backend."""

from __future__ import annotations

import asyncio
import time
from collections import defaultdict

from heisenberg.backend.logging import get_logger

logger = get_logger(__name__)


class SlidingWindowRateLimiter:
    """Sliding window rate limiter for API requests."""

    def __init__(self, requests_per_minute: int = 60):
        """
        Initialize rate limiter.

        Args:
            requests_per_minute: Maximum requests allowed per minute.
        """
        self.rpm = requests_per_minute
        self.requests: dict[str, list[float]] = defaultdict(list)
        self._locks: dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)

    async def is_allowed(self, key: str) -> tuple[bool, dict[str, str]]:
        """
        Check if a request is allowed for the given key.

        Args:
            key: Unique identifier for rate limiting (e.g., API key, IP).

        Returns:
            Tuple of (allowed, rate_limit_headers).
        """
        async with self._locks[key]:
            now = time.time()
            window_start = now - 60  # 1-minute sliding window

            # Clean old requests outside the window
            self.requests[key] = [t for t in self.requests[key] if t > window_start]

            current_count = len(self.requests[key])
            allowed = current_count < self.rpm

            if allowed:
                self.requests[key].append(now)
                remaining = self.rpm - current_count - 1
            else:
                remaining = 0

        headers = {
            "X-RateLimit-Limit": str(self.rpm),
            "X-RateLimit-Remaining": str(max(0, remaining)),
            "X-RateLimit-Reset": str(int(window_start + 60)),
        }

        if not allowed:
            logger.warning(
                "rate_limit_exceeded",
                key=key,
                limit=self.rpm,
                current_count=current_count,
            )

        return allowed, headers
```

**Plik:** `src/heisenberg/backend/middleware.py`

ZaktualizowaÄ‡ wywoÅ‚anie:

```python
# PRZED:
allowed, headers = self.limiter.is_allowed(key)

# PO:
allowed, headers = await self.limiter.is_allowed(key)
```

**RozwiÄ…zanie (etap 2 - Redis) - opcjonalne dla produkcji:**

Dla prawdziwej skalowalnoÅ›ci horyzontalnej rozwaÅ¼yÄ‡ migracjÄ™ do Redis z bibliotekÄ… `redis-py` lub uÅ¼ycie `slowapi` z backendem Redis.

---

## Faza 3: Konsolidacja kodu âœ…

> **ZakoÅ„czona 2026-01-25** | Implementacja TDD | 17 nowych testÃ³w | 785 testÃ³w passed

### 3.1 Ujednolicenie klientÃ³w LLM âœ…

**Problem:** Duplikacja miÄ™dzy `src/heisenberg/llm_client.py` (sync, CLI) a `src/heisenberg/backend/llm/*` (async, backend).

**RozwiÄ…zanie:**

#### Krok 1: UtworzyÄ‡ wspÃ³lnÄ… strukturÄ™ odpowiedzi

**Nowy plik:** `src/heisenberg/llm/models.py`

```python
"""Shared LLM response models."""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import ClassVar


# Pricing per million tokens (as of 2025)
PRICING: dict[str, dict[str, float]] = {
    "claude-3-5-sonnet-20241022": {"input": 3.0, "output": 15.0},
    "claude-sonnet-4-20250514": {"input": 3.0, "output": 15.0},
    "gpt-4o": {"input": 2.5, "output": 10.0},
    "gpt-4o-mini": {"input": 0.15, "output": 0.6},
    "gemini-1.5-pro": {"input": 1.25, "output": 5.0},
}

DEFAULT_INPUT_COST = 3.0
DEFAULT_OUTPUT_COST = 15.0


@dataclass
class LLMAnalysis:
    """Unified response from LLM analysis."""

    content: str
    input_tokens: int
    output_tokens: int
    model: str
    provider: str

    @property
    def total_tokens(self) -> int:
        """Total tokens used."""
        return self.input_tokens + self.output_tokens

    @property
    def estimated_cost(self) -> float:
        """Estimate cost in USD based on token usage."""
        pricing = PRICING.get(self.model, {})
        input_cost_per_million = pricing.get("input", DEFAULT_INPUT_COST)
        output_cost_per_million = pricing.get("output", DEFAULT_OUTPUT_COST)

        input_cost = self.input_tokens * input_cost_per_million / 1_000_000
        output_cost = self.output_tokens * output_cost_per_million / 1_000_000
        return input_cost + output_cost
```

#### Krok 2: ZaktualizowaÄ‡ backend providers

ZmieniÄ‡ `src/heisenberg/backend/llm/claude.py` (i inne providery) aby zwracaÅ‚y `LLMAnalysis`:

```python
from heisenberg.llm.models import LLMAnalysis

async def analyze(...) -> LLMAnalysis:
    # ... existing code ...
    return LLMAnalysis(
        content=response.content[0].text,
        input_tokens=response.usage.input_tokens,
        output_tokens=response.usage.output_tokens,
        model=model,
        provider=self.name,
    )
```

#### Krok 3: ZaktualizowaÄ‡ CLI client

ZmieniÄ‡ `src/heisenberg/llm_client.py` aby uÅ¼ywaÅ‚ `LLMAnalysis` zamiast `LLMResponse`.

---

## Faza 4: Architektura (opcjonalne)

### 4.1 PrzenieÅ›Ä‡ stan bazy danych do app.state

**Problem:** Globalne `_engine` i `_session_maker` komplikujÄ… testowanie.

**Plik:** `src/heisenberg/backend/database.py`

```python
"""Database connection and session management."""

from __future__ import annotations

from collections.abc import AsyncGenerator
from typing import TYPE_CHECKING

from sqlalchemy.ext.asyncio import (
    AsyncSession,
    async_sessionmaker,
    create_async_engine as _create_async_engine,
)

if TYPE_CHECKING:
    from fastapi import Request
    from sqlalchemy.ext.asyncio import AsyncEngine

from heisenberg.backend.config import Settings


def create_async_engine(database_url: str, echo: bool = False) -> AsyncEngine:
    """Create an async SQLAlchemy engine."""
    if database_url.startswith("postgresql://"):
        database_url = database_url.replace("postgresql://", "postgresql+asyncpg://", 1)

    return _create_async_engine(
        database_url,
        echo=echo,
        pool_pre_ping=True,
    )


def get_session_maker(engine: AsyncEngine) -> async_sessionmaker[AsyncSession]:
    """Create an async session maker."""
    return async_sessionmaker(
        bind=engine,
        class_=AsyncSession,
        expire_on_commit=False,
        autocommit=False,
        autoflush=False,
    )


def init_db(settings: Settings) -> tuple[AsyncEngine, async_sessionmaker[AsyncSession]]:
    """Initialize database and return engine and session maker."""
    engine = create_async_engine(settings.database_url, echo=settings.debug)
    session_maker = get_session_maker(engine)
    return engine, session_maker


async def get_db(request: Request) -> AsyncGenerator[AsyncSession, None]:
    """Dependency that yields database sessions from app state."""
    session_maker = getattr(request.app.state, "session_maker", None)
    if session_maker is None:
        raise RuntimeError("Database not initialized. Check DATABASE_URL.")

    async with session_maker() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
```

**Plik:** `src/heisenberg/backend/app.py`

```python
@asynccontextmanager
async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
    """Application lifespan manager."""
    from heisenberg.backend.config import get_settings
    from heisenberg.backend.database import init_db

    settings = get_settings()

    configure_logging(
        log_level=settings.log_level,
        json_format=settings.log_json_format,
    )

    if os.environ.get("DATABASE_URL"):
        engine, session_maker = init_db(settings)
        app.state.engine = engine
        app.state.session_maker = session_maker
        logger.info("database_initialized", database_url=settings.database_url[:20] + "...")

    logger.info("app_started", version=__version__)

    yield

    # Shutdown
    if hasattr(app.state, "engine"):
        await app.state.engine.dispose()
    logger.info("app_shutdown")
```

---

## Checklist implementacji

### Faza 1 (Quick Wins) âœ…
- [x] DodaÄ‡ `@lru_cache` do `get_settings()` â€” `src/heisenberg/backend/config.py`
- [x] ZawÄ™ziÄ‡ `except Exception` w `LLMRouter` â€” `src/heisenberg/backend/llm/router.py`
- [x] ZaktualizowaÄ‡ testy â€” `tests/test_phase1_refactoring.py` (nowy), `tests/test_backend_multi_llm.py`

### Faza 2 (SkalowalnoÅ›Ä‡) âœ…
- [x] DodaÄ‡ `asyncio.Lock` do rate limitera â€” `src/heisenberg/backend/rate_limit.py`
- [x] ZmieniÄ‡ `is_allowed()` na `async` â€” `src/heisenberg/backend/rate_limit.py`
- [x] ZaktualizowaÄ‡ middleware â€” `src/heisenberg/backend/middleware.py`
- [x] PrzetestowaÄ‡ pod obciÄ…Å¼eniem â€” `tests/test_phase2_refactoring.py` (12 testÃ³w), `tests/test_backend_rate_limit.py` (zaktualizowane)

### Faza 3 (Konsolidacja) âœ…
- [x] UtworzyÄ‡ `src/heisenberg/llm/models.py` â€” z `LLMAnalysis` dataclass i `PRICING` dict
- [x] ZaktualizowaÄ‡ backend providers â€” `claude.py`, `openai.py`, `router.py`, `base.py`
- [x] ZaktualizowaÄ‡ CLI client â€” `llm_client.py` z aliasem `LLMResponse = LLMAnalysis`
- [x] ZaktualizowaÄ‡ adapter â€” `adapter.py` uproszczony, uÅ¼ywa bezpoÅ›rednio `LLMAnalysis`
- [x] PrzetestowaÄ‡ â€” `tests/test_phase3_refactoring.py` (17 testÃ³w), istniejÄ…ce testy zaktualizowane

### Faza 4 (Architektura)
- [ ] PrzenieÅ›Ä‡ stan DB do `app.state`
- [ ] ZaktualizowaÄ‡ dependency `get_db()`
- [ ] ZaktualizowaÄ‡ testy integracyjne

---

## Uwagi koÅ„cowe

- KaÅ¼da faza moÅ¼e byÄ‡ wdroÅ¼ona niezaleÅ¼nie
- Faza 1 powinna byÄ‡ priorytetem ze wzglÄ™du na niski wysiÅ‚ek i natychmiastowe korzyÅ›ci
- Faza 4 jest opcjonalna - obecne rozwiÄ…zanie dziaÅ‚a, ale utrudnia testowanie
- Przed wdroÅ¼eniem Fazy 2 rozwaÅ¼yÄ‡ czy aplikacja faktycznie bÄ™dzie dziaÅ‚aÄ‡ na wielu workerach
